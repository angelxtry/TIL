# 01. 한눈에 보는 머신러닝

- 광학 문자 판독기 OCR
- 스팸 필터
- 추천
- 음성 검색

## 1.1 머신러닝이란

- 머신러닝은 데이터로부터 학습하도록 컴퓨터를 프로그래밍하는 것
- 명시적인 프로그래밍 없이 컴퓨터가 학습하는 능력을 갖추가 하는 연구 분야.
- 어떤 작업 T에 대한 컴퓨터 프로그램의 성능을 P로 측정했을 때 경험 E로 인해 성능이 향상됐다면, 이 컴퓨터 프로그램은 작업 T와 성능 측정 P에 대한 경험 E로 학습한 것이다.

- 시스템이 학습하는 데 사용하는 샘플을 훈련 세트(training set)
- 각 훈현 데이터를 훈련 사례(training instance) 혹은 샘플

- 새로운 메일이 스팸인지 구분하는 것을 작업 T
- 경험 E는 훈련 데이터 training data
- 성능 측정 P는 직접 정의한다.
- 예를 들면 정확히 분류된 메일의 비율을 P로 사용할 수 있다.
- 이 성능 측정을 정확도 accuracy라고 부른다.

- 머신러닝 기술을 적용해서 대용량의 데이터를 분석하면 겉으로는 보이지 않던 패턴을 발견할 수 있다. 이를 데이터 마이닝(data mining)이라고 한다.

## 1.3 머신러닝 시스템의 종류

- 사람의 감독 하에 훈련하는 것인가 - 지도, 비지도, 준지도, 강화 학습
- 실시간으로 점진적인 학습을 하는가 - 온라인 학습과 배치 학습
- 단순하게 알고 있는 데이터 포인트와 새 데이터 포인트를 비교하는 것인가 아니면 훈련 데이터셋에서 과학자들처럼 패턴을 발견하여 예측 모델을 만드는가 - 사례 기반 학습과 모델 기반 학습
- 이 범주들은 서로 배타적이지 않으면 원하는 대로 연결할 수 있다.

### 1.3.1 지도 학습과 비지도 학습

- 머신러닝 시스템을 학습하는 동안의 감독 형태나 정보량에 따라 분류

#### 지도 학습(supervised learning)

- 지도 학습에는 알고리즘에 주입하는 훈련 데이터에 레이블(label)이라는 원하는 답이 포함된다.
- 분류(classification)가 전형적인 지도 학습 작업이며, 스팸 필터가 좋은 예다.

- 또 다른 전형적인 작업은 예측 변수(predictor variable)라 부르는 특성(feature)(주행거리, 연식, 브랜드 등)을 사용해 중고차 가격 같은 타깃 수치를 예측하는 것.
- 이런 종류의 작업을 회귀(regression)라고 부른다.
- 시스템을 훈련시키려면 예측 변수와 레이블(중고차 가격)이 포함된 중고차 데이터가 많이 필요하다.

- 일부 회귀 알고리즘은 분류에 사용할 수도 있고 다른 용도로 사용될 수도 있다.
- 예를들어 분류에 널리 쓰이는 로지스틱 회귀는 클래스에 속할 확률을 출력한다.

- 주요 지도 학습 알고리즘
  - k-최근접 이웃 k-Nearest Neighbors
  - 선형 회귀 Linear Regression
  - 로지스틱 회귀 Logistic Regression
  - 서포트 벡터 머신 Support Vector Machines SVM
  - 결정 트리 Decision Tree
  - 랜덤 포레스트 Random Forests
  - 신경망 Nerual networks

#### 비지도 학습 unsupervised learning

- 비지도 학습은 훈련 데이터에 레이블이 없다.
- 시스템에 아무런 도움 없이 학습해야 한다.

- 비지도 학습 알고리즘
  - 군집 clustering
    - k-평균 k-Means
    - 계층 군집 분석 Hierachical Cluster Analysis HCA
    - 기대값 최대화 Expectation Maximization
  - 시각화 visualization와 차원 축소 dimensionality reduction
    - 주성분분석 Principal Component Analysis PCA
    - 커널 kernel
    - 지역적 선형 임베딩 Locally-Linear Embedding LLE
    - t-SNE t-distributed Stochastic Neighbor Embedding
  - 연관 규칙 학습 Association rule learning
    - 어프라이어리 Apriori
    - 이클렛 Eclat

- 예를 들어 불로그 방문자에 대한 데이터가 많이 있다고 가정하자.
- 비슷한 방문자들을 그룹으로 묶기 위해 군집 알고리즘을 적용한다.
- 방문자가 어떤 그룹에 속하는지 알고리즘에 알려줄 수 있는 데이터 포인트가 없을 경우 알로리즘이 방문자 사이의 연결고리를 찾는다.
- 계층 군집 hierarchical clustering 알고리즘을 사용하면 각 그룹을 더 작은 그룹으로 세분화할 수 있다.

- 시각화 알고리즘도 비지도 학습 알고리즘의 좋은 예다.

- 너무 많은 정보를 잃지 않으면서 데이터를 간소화하려는 차원 축소 dimensionality reduction
- 예를 들어 차의 주행거리는 연식과 매우 연관되어 있으므로 차원 축소 알고리즘으로 두 특성을 차의 마모 정도를 나타내는 하나의 특성으로 합칠 수 있다.
- 이를 특성 추출(feature extraction)이라고 한다.

- 지도 학습 알고리즘 같은 머신러닝 알고리즘에 데이터를 주입하기 전에 차원 축소 알고리즘을 사용하여 훈련 데이터의 차원을 줄이는 것이 유용할 때가 많다.

- 중요한 비지도 학습 중 하나는 이상치 탐지 anomalay detection
- 시스템은 정상 샘플로 훈련되고, 새로운 샘플이 정상 데이터인지 아닌지 판단한다.

- 널리 사용되는 또 다른 비지도 학습은 대량의 데이터에서 특성 간의 관계를 찾는 연관 규칙 학습 association rule learning이다.
- 판매 기록에 연관 규칙을 적용하면 바비큐 소스와 감자를 구매한 사람이 스테이크도 구매하는 경향이 있다는 것을 찾을 수 있다.
- 연관 규칙은 규칙 기반 rule-based 학습의 한 종류로 사이킷런에서는 제공하지 않는다.

#### 준지도 학습 semisupervised learning

- 레이블이 일부만 있는 데이터
- 구글 포토가 대표적인 예
- 사람마다 레이블이 하니씩만 주어지면 다른 사진에 있는 동일한 사람의 이름을 알 수 있고, 사람으로 사진을 찾을 수 있다.

- 대부분의 준지도 학습 알고리즘은 지도 학습과 비지도 학습의 조합으로 이루어져 있다.
- 예를 들어 심층 신뢰 신경망 deep belief network DBN은 여러 겹으로 쌓은 제한된 볼츠만 머신 restricted Boltzmann machine RBM 이라 불리는 비지도 학습에 기초한다.

#### 강화 학습 reinforcement learning

- 강화 학습은 매우 다른 종류의 알고리즘이다.
- 학습하는 시스템을 에이전트라고 부르고 환경 environment을 관찰해서 행동 action을 실행하고 그 결과로 보상 reward(또는 부정적인 보상에 해당하는 벌점 penalty)을 받는다.
- 시간이 지나면서 가장 큰 보상을 얻기 위해 정책 policy이라고 부르는 최상의 전략을 스스로 학습한다.
- 정책은 주어진 상황에서 에이전트가 어떤 행동을 선택해야 할지 정의한다.
- 보행 로봇을 만들기 위해 강화 학습 알고리즘을 많이 사용한다.
- DeepMind의 AlphaGo도 강화 학습의 예다.

### 배치 학습과 온라인 학습

- 머신러닝 시스템을 분라하는 데 사용하는 다른 기준은 입력 데이터의 스트림으로부터 점진적으로 학습할 수 있는지 여부다.

#### 배치 학습 batch learning

- 배치 학습에서는 시스템이 점진적으로 학습할 수 없다.
- 일반적으로 이 방식은 시간과 자원을 많이 소모하므로 보통 오프라인에서 수행된다.
- 먼저 시스템을 훈련시키고 그런 다음 제품 시스템에 적용하면 더 이상의 학습 없이 실행된다.
- 그래서 오프라인 학습 offline learning 이라고 한다.

- 데이터 양이 아주 많으면 배치 학습 알고리즘을 사용하는게 불가능할 수도 있다.

#### 온라인 학습

- 데이터를 순차적으로 한 개씩 또는 미니배치 mini-batch라 부르는 작은 묶음 단위로 주입하여 훈련시킨다.
- 매 학습 단계가 빠르고 비용이 적게 들어 시스템은 데이터가 도착하는 대로 즉시 학습할 수 있다.

- 온라인 흑습 시스템에서 중요한 파라미터 하나는 변화하는 데이터에 얼마나 빠르게 적응할 것인가다.
- 이를 학습률 learning rate라고 한다.
- 학습률을 높게 하면 시스템이 데이터에 빠르게 적응하지만 예전 데이터를 금방 잊어버린다.
- 학습률이 낮으면 시스템의 관성이 더 커져서 더 느리게 학습된다.

- 온라인 학습에서 가장 큰 문제점은 시스템에 나쁜 데이터가 주입되었을 때 시스템 성능이 점진적으로 감소한다는 점이다.
- 이상치 탐지 알고리즘 등을 사용해서 비정상 데이터를 잡아내는 방식이 필요하다.

### 1.3.3 사례 기반 학습과 모델 기반 학습

- 어떻게 일반화되는가에 따라 분류
- 대부분의 머신러닝 작업은 예측을 만드는 것
- 이 말은 주어진 훈련 데이터로 학습하지만 훈련 데이터에서는 본 적 없는 새로운 데이터로 일반화되어야 한다는 뜻

#### 사례 기반 학습 instacne-based learning

- 스팸 메일과 동일한 메일을 스팸이라고 지정하는 대신 스팸 메일과 매우 유사한 메일을 구분하도록 스팸 필터를 프로그램할 수 있다.
- 잉렇게 하려면 유사도 similarity를 측정해야 한다.
- 예를들어 두 메일 사이의 유사도를 측정하기 위해 공통으로 포함한 단어의 수를 세는 방법
- 시스템이 사례를 기억함으로써 학습한다.
- 그리고 유사도 측정을 사용해 새로운 데이터에 일반화한다.

#### 모델 기반 학습 model-based learning

- 행복과 GDP
- 삶의 만족도는 국가의 1인당 GDP가 증가할수록 거의 선형으로 같이 올라간다.

- 모델이 얼마나 좋은지 측정하는 효용 함수 utility function 또는 적합도 함수 fitness function를 정의하거나 얼마나 나쁜지 측정하는 비용 함수 cost function를 정의할 수 있다.
