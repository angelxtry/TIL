# 04. 이터레이터와 제네레이터

## 4.11 여러 시퀀스 동시에 순환

* 여러 시퀀스를 동시에 순환하려면 zip() 함수를 사용한다.

```py
xpts = [1, 2, 3, 4, 5]
ypts = [6, 7, 8, 9, 10]
for x, y in zip(xpts, ypts):
    print(x, y)
```

* zip(a, b)는 tuple(x, y)를 생성하는 이터레이터를 생성한다.
* 한쪽 시퀀스의 모든 입력이 소비되었을 때 정지한다.
* itertools.zip_longest()를 사용하면 길이가 긴 시퀀스의 입력에 맞춘다.

```py
from itertools import zip_longest

xpts = [1, 2, 3, 4, 5]
ypts = [6, 7, 8, 9, 10, 11]
for p in zip_longest(xpts, ypts):
    print(p)
```

```sh
(1, 6)
(2, 7)
(3, 8)
(4, 9)
(5, 10)
(None, 11)
```

* zip()을 사용하면 두 값을 묶어 dictionary로 만들 수 있다.

```py
from itertools import zip_longest

xpts = [1, 2, 3, 4, 5]
ypts = [6, 7, 8, 9, 10, 11]

d = dict(zip_longest(xpts, ypts))
print(d)
```

* zip()에 시퀀스를 두 개 이상 입력할 수 있다.

## 4.12 서로 다른 컨테이너 아이템 순환

* itertools.chain() 메소드를 사용한다.
* 이 메소드는 순환 가능한 객체를 리스트로 받고 마스킹을 통해 한번에 순환할 수 있는 이터레이터를 반환한다.

```py
from itertools import chain

a = [1, 2, 3]
b = ['a', 'b', 'c']
for x in chain(a, b):
    print(x)
```

* 두 개의 시퀀스를 합친 새로운 시퀀스를 만드는 것 보다 chain()을 사용하는 것이 더 효율적이다.

## 데이터 처리 파이프라인 생성

* 처리해야 할 방대한 데이터가 있지만 메모리에 한꺼번에 들어가지 않는 경우에 적용할 수 있다.

```py
import os
import fnmatch
import gzip
import bz2
import re

def gen_find(filepat, top):
    '''
    디렉터리 트리에서 와일드카드 패턴에 매칭하는 모든 파일 이름을 찾는다.
    '''
    for path, dirlist, filelist in os.walk(top):
        for name in fnmatch.filter(filelist, filepat):
            yield os.path.join(path, name)

def gen_opener(filenames):
    '''
    파일 이름 시퀀스를 하나씩 열어 파일 객체를 생성한다.
    다음 순환으로 넘어가는 순간 파일을 닫는다.
    '''
    for filename in filenames:
        if filename.endswith('.gz'):
            f = gzip.open(filename, 'rt')
        elif filename.endswith('.bz2'):
            f = bz2.open(filename, 'rt')
        else:
            f = open(filename, 'rt')
        yield f
        f.close()

def gen_concatenate(iterators):
    '''
    이터레이터 시퀀스를 합쳐 하나의 시퀀스로 만든다.
    '''
    for it in iterators:
        yield from it

def gen_grep(pattern, lines):
    '''
    라인 시퀀스에서 정규식 패컨을 살펴본다.
    '''
    pat = re.compile(pattern)
    for line in lines:
        if pat.search(line):
            yield line


lognames = gen_find('access-log*', 'www')
files = gen_opener(lognames)
lines = gen_concatenate(files)
pylines = gen_grep('(?i)python', lines)
for line in pylines:
    print(line)
```

* python이란 단어를 포함하고 있는 모든 로그 라인을 찾는다.

```py
bytecolumn = (line.rsplit(None, 1)[1] for line in pylines)
bytes = (int(x) for x in bytecolumn if x != '-')
print('Total: ', sum(bytes))
```

* 파이프라인으로 데이터를 처리하는 방식은 파싱, 실시간 데이터 읽기, 주기적 폴링 등 다른 문제에도 사용할 수 있다.
* yield 문이 데이터 생성자처럼 동작하고 for 문은 데이터 소비자처럼 동작한다.
* gen_concatenate() 함수의 목적은 입력받은 시퀀스를 하나로 합치는 것이다.
* itertools.chain() 함수가 비슷한 기능이지만, 이 함수는 묶어 줄 모든 순환 객체를 인자로 전달해야 한다.
* 하지만 chain()을 사용하면 다음 번 순환 단계에서 곧바로 닫는 파일 시퀀스를 생성하기 때문에 부적합하다.
* 또한 gen_concatenate() 함수는 서브제너레이터에 대한 델리케이드로 yield from을 활용한다(뭔소릴까?)
* yield from 문은 gen_concatenate()가 제너레이터 it이 생성한 모든 값을 분출하도록 만든다.

## 4.14 중첩 시퀀스 풀기

```py
from collections import Iterable

def flatten(items, ignore_types=(str, bytes)):
    for x in items:
        if isinstance(x, Iterable) and not isinstance(x, ignore_types):
            yield from flatten(x)
        else:
            yield x

items = [1, 2, [3, 4, [5, 6], 7], 8]
for x in flatten(items):
    print(x)
```

* isinstance(x, Iterable)은 아이템이 순환 가능한 것인지 확인한다.
* 순환이 가능하다면 yield from으로 모든 값을 하나의 서브루틴으로 분출한다.
* ignore_types와 not isinstance(x, ignore_types)로 문자열곽 바이트가 순환 가능한 것으로 해석되지 않도록 했다.
* 이렇게 해야만 리스트에 담겨 있는 문자열을 전달했을 때 문자를 펼치지 않고 문자열 단위로 전개한다.
* yield from을 사용하지 않으면 추가적인 for 문이 있는 코드를 작성해야 한다.

```py
if isinstance(x, Iterable) and not isinstance(x, ignore_types):
    for i in flatten(x):
        yield i
```

## 4.15 정렬된 여러 시퀀스를 병합 후 순환

* heapq.merge() 함수를 사용하면 된다.

```py
import heapq

a = [1, 3, 5, 7]
b = [2, 4, 6, 8]
for c in heapq.merge(a, b):
    print(c)
```

* heapq.merge()는 아이템에 순환적으로 접근하며 제공한 시퀀스를 한꺼번에 읽지 않는다.
* 예를 들어 정렬된 두 파일을 병합하려면 다음과 같이 한다.

```py
import heapq

with open('sorted_file_1', 'rt') as file1, \
     open('sorted_file_2', 'rt') as file2. \
     open('merged_file', 'wt') as outf:
     for line in heapq.merge(file1, file2):
         outf.write(line)
```

* heapq.merge()에 넣는 시퀀스는 모두 정렬되어 있어야 한다.
* 이 함수에 전달한다고 우선적으로 정렬을 하지 않는다.
* 단지 앞에서부터 읽어 가면서 가장 작은 것부터 데이터를 출력할 뿐이다.

## 4.16 무한 while 순환문을 이터레이터로 치환

* 입출력과 관련 있는 프로그램은 일반적으로 while 무한 루프를 사용한다.

```py
CHUNKSIZE = 8192

def reader(s):
    while True:
        data = s.recv(CHUNKSIZE)
        if data == b'':
            break
        process_data(data)
```

* while문을 iter()를 사용해 다음과 같이 수정할 수 있다.

```py
def reader(s):
    for chunk in iter(lambda: s.recv(CHUNKSIZE), b''):
        n = sys.stdout.write(chunk)
```

* iter() 함수는 선택적으로 인자 없는 호출 가능 객체와 종료 값을 입력으로 받는다.
* 이렇게 사용하면 주어진 종료 값을 반환하기 전까지 문한히 반복해서 호출 가능 객체를 호출한다.
* 예를 들어 소켓이나 파일에서 특정 크기의 데이터를 읽으려 한다면, 반복적으로 read()나 recv()를 호출하고 파일 끝(end of file)을 확인해야 한다.
* iter()를 사용하면 두 가지 동작을 하나로 합칠 수 있다.
* lambda를 사용하면 인자를 받지 않는 호출 객체를 만들 수 있고 원하는 크기의 인자를 recv()나 read()에 전달한다.
