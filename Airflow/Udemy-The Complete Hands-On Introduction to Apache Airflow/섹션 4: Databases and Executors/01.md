# 섹션 4: Databases and Executors

동시에 task를 실행하려면?

이번 장의 질문

1. 동시에 task를 실행할 수 있을까?
2. 알아둬야한 중요한 parameter?
3. scaling을 위해 사용하는 executor?

## default configuration

```py
> airflow config get-value core sql_alchemy_conn
mysql://gomicorp:gomismile2019@127.0.0.1:3306/airflow
```

```py
> airflow config get-value core executor
SequentialExecutor
```

```py
from airflow import DAG
from airflow.operators.bash import BashOperator

from datetime import datetime

default_args = {
    'start_date': datetime(2021, 1, 1)
}

with DAG('parallel_dag', schedule_interval='@daily', default_args=default_args, catchup=False) as dag:

    task_1 = BashOperator(
        task_id='task_1',
        bash_command='sleep 3'
    )

    task_2 = BashOperator(
        task_id='task_2',
        bash_command='sleep 3'
    )

    task_3 = BashOperator(
        task_id='task_3',
        bash_command='sleep 3'
    )

    task_4 = BashOperator(
        task_id='task_4',
        bash_command='sleep 3'
    )

    task_1 >> [task_2, task_3] >> task_4
```

web에서 해당 DAG의 Graph View에서 Auto-refresh를 활성화하고 dag를 실행하면 실시간으로 어떤 task가 실행되는지 확인된다.

모두 실행 된 뒤 Gantt를 확인하면 순차적으로 실행된 것을 볼 수 있다.

동시 실행을 위해 mysql 또는 postgres가 필요하다.

```py
pip install 'apache-airflow[mysql]'
or
pip install 'apache-airflow[postgres]'
```

airflow.cfg 파일을 수정한다.

```py
sql_alchemy_conn = mysql://[DB_USER]:[DB_PASSWORD]@127.0.0.1:3306/[DB_DATABASE]
```

변경 후 다음의 cmd로 확인한다.

```py
airflow db check
```

airflow.cfg 파일의 executor를 수정한다.

```py
# 변경 전
executor = SequentialExecutor

# 변경 후
executor = LocalExecutor
```

DB를 변경했다면 다음의 cmd를 입력한다.

```py
airflow db init
```

scheduler도 다시 실행한다.

web에서 parallel_dag를 다시 실행해보면 Graph View와 Gantt에서 task_2, task_3이 동시에 실행되는 것을 확인할 수 있다.


## 31. Scale to the infinity with the Celery Executorㄴ

- `set number` or `set nu` 화면에 행넘버를 출력한다.
- `set relativenumber` or `set rnu` 현재 위치를 0으로 하는 상대적인 행넘버를 출력한다.
- `set nonumber` or `set nu!` 행넘버를 보이지 않게 한다.
- `set norelativenumber` or `set nornu` 상대적인 행넘버를 보이지 않게 한다.